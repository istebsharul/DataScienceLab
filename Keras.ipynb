{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "36gzyj9ZBK4a"
      },
      "outputs": [],
      "source": [
        "from numpy import loadtxt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset= loadtxt('pima-indians-diabetes.data.csv', delimiter=',')\n",
        "X=dataset[:,0:8]\n",
        "y=dataset[:,8]"
      ],
      "metadata": {
        "id": "vbLs_SypCI_Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Section"
      ],
      "metadata": {
        "id": "qcLnJcJoqT-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "yWlepQD5qUeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "pzwpSPG9CNdP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "TR_4iaD4XQHc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y, epochs=150, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa2nmWjRZLPH",
        "outputId": "12cc0e65-b8f8-494d-90e0-6819dbefc371"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 3.3638 - accuracy: 0.4779\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 1.0142 - accuracy: 0.6172\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7721 - accuracy: 0.6107\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7252 - accuracy: 0.6380\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.6367\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.6602\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.6784\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.6706\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6836\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6654\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6940\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.6888\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6888\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.7005\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.7018\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6979\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.7018\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6966\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7031\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.7057\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.7135\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.7148\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.7214\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.7070\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7083\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7005\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7174\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.7070\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.7214\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7188\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.7240\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7227\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7383\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.7214\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7357\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7266\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7305\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7214\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7174\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7240\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7305\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7174\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5515 - accuracy: 0.7344\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7253\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7279\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7161\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7370\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7083\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7331\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7370\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7344\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7357\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7422\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7292\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7227\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7370\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7370\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7383\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7435\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7487\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7344\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7370\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7331\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5479 - accuracy: 0.7461\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7279\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5338 - accuracy: 0.7500\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7422\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7461\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7435\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7513\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7409\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7422\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7370\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7591\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7461\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7396\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7513\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7487\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7448\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 0.7604\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7513\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7448\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7669\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7448\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7448\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7630\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7500\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7513\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7552\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7604\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7578\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7604\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7513\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7565\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7526\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7318\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7630\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7656\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7461\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7617\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7539\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7513\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7578\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7578\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7526\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7526\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7474\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7526\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7591\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7539\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7513\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7708\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7708\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7669\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7617\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7513\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.7656\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7630\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7604\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.7630\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7565\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7630\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7526\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7461\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7721\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7604\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7591\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7552\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7656\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7604\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7617\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7565\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7656\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7734\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7682\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7591\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7604\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7617\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7578\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7669\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7630\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7591\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7721\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7708\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7656\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7604\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7552\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7852\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7552\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7760\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb2ac1c74f0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# Define a list of sentences or text corpus for training Word2Vec\n",
        "corpus = [\n",
        "    \"I enjoy playing football\",\n",
        "    \"Football is my favorite sport\",\n",
        "    \"I love watching football matches\"\n",
        "]\n",
        "\n",
        "# Preprocess the corpus by tokenizing the sentences\n",
        "tokenized_corpus = [simple_preprocess(sentence) for sentence in corpus]\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec(tokenized_corpus, min_count=1)\n",
        "\n",
        "# Get the word vector for a specific word\n",
        "word = \"football\"\n",
        "word_vector = model.wv[word]\n",
        "print(f\"Word Vector for '{word}':\")\n",
        "print(word_vector)\n",
        "\n",
        "# Find similar words based on the cosine similarity of word vectors\n",
        "similar_words = model.wv.most_similar(word)\n",
        "print(f\"\\nSimilar words to '{word}':\")\n",
        "for w, sim in similar_words:\n",
        "    print(w, sim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7_NqAc4qWYm",
        "outputId": "f8b28581-4434-462d-a8b6-bf60a64dd0ce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Vector for 'football':\n",
            "[-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
            " -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
            " -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
            " -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
            "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
            "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
            "  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
            " -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
            "  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
            "  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
            " -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
            " -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
            "  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
            " -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
            "  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
            " -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
            " -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
            " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
            " -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
            "  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
            " -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
            " -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
            " -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
            "  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
            " -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n",
            "\n",
            "Similar words to 'football':\n",
            "enjoy 0.21617142856121063\n",
            "is 0.09291722625494003\n",
            "playing 0.027057476341724396\n",
            "my 0.016134677454829216\n",
            "matches -0.01083916611969471\n",
            "sport -0.027750369161367416\n",
            "watching -0.05234673246741295\n",
            "favorite -0.059876296669244766\n",
            "love -0.111670583486557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cROVVLt9-VCe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}